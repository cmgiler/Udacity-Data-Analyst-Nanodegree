{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3. OpenStreetMap Case Study - Milwaukee, WI\n",
    "## Map Area\n",
    "Milwaukee, WI, United States\n",
    "- https://www.openstreetmap.org/relation/251075\n",
    "- https://s3.amazonaws.com/metro-extracts.mapzen.com/milwaukee_wisconsin.osm.bz2\n",
    "\n",
    "I selected Milwaukee because it is has been recommended to me by some friends recently as an interesting and underrated city to visit. I decided to use it for this project to see what the city has to offer, in preparation for a future visit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems Encountered\n",
    "Through analysis of a small sample of the map, the data appeared to be very clean. However, on my first scan of the entire xml document, I came across a few issues with the data:\n",
    "- Inconsistent street name abbreviations (ex: \"Street\" vs \"St\" vs \"St.\"; or \"Ave\" vs \"Ave.\")\n",
    "- Street names containing postal code information\n",
    "- Inconsistent numeric postal code formats (\"XXXXX\" vs \"XXXXX-XXXX\")\n",
    "- Postal codes containing non-numeric information (ex. \"WI\" as value of postal code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditing Data and Determining Necessary Cleaning Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages needed for xml parsing and data printing\n",
    "import xml.etree.ElementTree as ET\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set file name\n",
    "# OSM_FILE = 'milwaukee_wisconsin.osm'\n",
    "OSM_FILE = 'milwaukee_sample.osm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count number of tags in selected OSM xml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 9972,\n",
      " 'nd': 1039528,\n",
      " 'node': 840763,\n",
      " 'osm': 1,\n",
      " 'relation': 996,\n",
      " 'tag': 519564,\n",
      " 'way': 94038}\n"
     ]
    }
   ],
   "source": [
    "def childTags(parent, tags={}):\n",
    "    '''Return all child tags within parent tag\n",
    "    \n",
    "    parent -- name of parent tag\n",
    "    '''\n",
    "    for child in parent:\n",
    "        tags = childTags(child, tags)\n",
    "    if parent.tag in tags:\n",
    "        tags[parent.tag] += 1\n",
    "    else:\n",
    "        tags[parent.tag] = 1\n",
    "    return tags\n",
    "\n",
    "def count_tags(filename):\n",
    "    '''Return number of each tag found in xml file\n",
    "    \n",
    "    filename -- XML File Name (string)\n",
    "    '''\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    tags = {}\n",
    "    tags = childTags(root)\n",
    "    return tags\n",
    "\n",
    "tags = count_tags(OSM_FILE)\n",
    "pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audit street names and postal codes for unexpected formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Look at street names for unexpected issues\n",
    "import re\n",
    "from collections import defaultdict\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = ['Street', 'Avenue', 'Boulevard', 'Drive', 'Court', 'Lane', 'Place', 'Road', \n",
    "            'Parkway', 'Square', 'Way', 'Pointe', 'Circle', 'Trail']\n",
    "\n",
    "def is_street_name(elem):\n",
    "    '''Outputs \"true\" if input element attribute == \"addr:street\"'''\n",
    "    return (elem.attrib['k'] == 'addr:street')\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Also audit issues with postcodes\n",
    "postcode_re = re.compile(r'^\\d{5}$')\n",
    "\n",
    "def is_postcode_name(elem):\n",
    "    return(elem.attrib['k'] == 'addr:postcode')\n",
    "\n",
    "def audit_postcode_name(postcode_names, postcode):\n",
    "    m = postcode_re.search(postcode)\n",
    "    if not m:\n",
    "        postcode_names[postcode].add(postcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    postcode_names = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events = (\"start\",)):\n",
    "        if elem.tag == 'way':\n",
    "            for tag in elem.iter('tag'):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "                elif is_postcode_name(tag):\n",
    "                    audit_postcode_name(postcode_names, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types, postcode_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "st_types, pc_names = audit(OSM_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'164': {'HWY 164', 'N6620 HWY 164', 'State Road 164'},\n",
       "             '31': {'State Highway 31'},\n",
       "             '41': {'Highway 41'},\n",
       "             '53076': {'53076'},\n",
       "             '83': {'North Highway 83'},\n",
       "             'Ave': {'E Wisconsin Ave',\n",
       "              'Milwaukee Ave',\n",
       "              'N. Prospect Ave',\n",
       "              'North Murray Ave',\n",
       "              'North Summit Ave',\n",
       "              'S Howell Ave',\n",
       "              'Summit Ave',\n",
       "              'W Appleton Ave',\n",
       "              'W Fond du Lac Ave',\n",
       "              'W Grand Ave',\n",
       "              'W Layton Ave',\n",
       "              'Wisconsin Ave'},\n",
       "             'Ave.': {'E. North Ave.',\n",
       "              'N. Prospect Ave.',\n",
       "              'North Oakland Ave.',\n",
       "              'W. Michigan Ave.'},\n",
       "             'Blvd': {'N Grandview  Blvd'},\n",
       "             'Ct': {'Manchester Ct', 'W Oakwood Part Ct'},\n",
       "             'Dr': {'Dr Martin Luther King Dr',\n",
       "              'E Capitol Dr',\n",
       "              'N9581 Bancroft Dr',\n",
       "              'W Sunset Dr'},\n",
       "             'NN': {'County Highway NN'},\n",
       "             'O': {'County Road O'},\n",
       "             'Pkwy': {'Miller Pkwy'},\n",
       "             'Rd': {'Golf Rd', 'N Port Washington Rd', 'West County Line Rd'},\n",
       "             'Rd.': {'N. Industrial Rd.', 'N. Port Washington Rd.'},\n",
       "             'St': {'21st St',\n",
       "              'E Sumner St',\n",
       "              'N 124th St',\n",
       "              'N Main St',\n",
       "              'N Pine St',\n",
       "              'N Rochester St',\n",
       "              'N Weil St',\n",
       "              'S 13th St',\n",
       "              'W Sumner St'},\n",
       "             'St.': {'N. Commerce St.', 'N. Weil St.', 'S. Jefferson St.'},\n",
       "             'W': {'Highway W'},\n",
       "             'West': {'Highway 167 West'}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List street types / names\n",
    "st_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of inconsistencies in street names. Some street types are abbreviated while others aren't (ex: \"Street\" vs. \"St\"). To solve this, abbreviated street types will be mapped to their unabbreviated forms. Street names with unusual street types (for example, numeric street types) will be mapped on a case-by-case basis.\n",
    "\n",
    "There is one street name which contained only a postal code. To avoid a chance of error by including this point, this node will be omitted from importing to our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'1729': {'1729'},\n",
       "             '53202-2001': {'53202-2001'},\n",
       "             '53203-3002': {'53203-3002'},\n",
       "             '53212-3839': {'53212-3839'},\n",
       "             '53212-4099': {'53212-4099'},\n",
       "             '53403-9998': {'53403-9998'},\n",
       "             'WI': {'WI'}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List unusual postal codes\n",
    "pc_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the database, we will try to keep the numeric format of postal codes consistent for all points. Therefore, postal codes found that do not match the common \"XXXXX\" numeric format are mapped to the correct format if possible or skipped if this conversion is not obvious"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mappings for street names and postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mapping_street_name = {'Ave': 'Avenue', \n",
    "           'Ave.': 'Avenue',\n",
    "           'Blvd': 'Boulevard',\n",
    "           'Ct': 'Court',\n",
    "           'Dr': 'Drive', \n",
    "           'Pkwy': 'Parkway',\n",
    "           'Rd': 'Road',\n",
    "           'Rd.': 'Road',\n",
    "           'St': 'Street',\n",
    "           'St.': 'Street'}\n",
    "\n",
    "changes_street_name = {'HWY 164': 'Highway 164',\n",
    "                       'N6620 HWY 164': 'N6620 Highway 164'}\n",
    "\n",
    "skip_street_name = ['53076']\n",
    "\n",
    "mapping_postcode = {'53202-2001': '53202',\n",
    "                    '53203-3002': '53203',\n",
    "                    '53212-3839': '53212',\n",
    "                    '53212-4099': '53212',\n",
    "                    '53403-9998': '53403',\n",
    "                    '53217-5399': '53217',\n",
    "                    '\"Milwaukee WI, 53222\"': '53222'}\n",
    "skip_postcode = ['WI', '1729']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Update street names and postcodes\n",
    "def update_street_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        if (m.group() == '164') and (name in mapping.keys()):\n",
    "            name = mapping[name]\n",
    "        else:\n",
    "            name = street_type_re.sub(mapping[m.group()], name)\n",
    "        return name\n",
    "\n",
    "def update_postcode(name, mapping):\n",
    "    m = postcode_re.search(name)\n",
    "    if not m:\n",
    "        if name in mapping.keys():\n",
    "            name = mapping[name]\n",
    "            return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E. North Ave. => E. North Avenue\n",
      "N. Prospect Ave. => N. Prospect Avenue\n",
      "W. Michigan Ave. => W. Michigan Avenue\n",
      "North Oakland Ave. => North Oakland Avenue\n",
      "S. Jefferson St. => S. Jefferson Street\n",
      "N. Weil St. => N. Weil Street\n",
      "N. Commerce St. => N. Commerce Street\n",
      "S 13th St => S 13th Street\n",
      "N 124th St => N 124th Street\n",
      "N Main St => N Main Street\n",
      "E Sumner St => E Sumner Street\n",
      "N Pine St => N Pine Street\n",
      "N Rochester St => N Rochester Street\n",
      "N Weil St => N Weil Street\n",
      "W Sumner St => W Sumner Street\n",
      "21st St => 21st Street\n",
      "West County Line Rd => West County Line Road\n",
      "N Port Washington Rd => N Port Washington Road\n",
      "Golf Rd => Golf Road\n",
      "N Grandview  Blvd => N Grandview  Boulevard\n",
      "HWY 164 => Highway 164\n",
      "N6620 HWY 164 => N6620 Highway 164\n",
      "W Grand Ave => W Grand Avenue\n",
      "North Murray Ave => North Murray Avenue\n",
      "W Fond du Lac Ave => W Fond du Lac Avenue\n",
      "W Layton Ave => W Layton Avenue\n",
      "Milwaukee Ave => Milwaukee Avenue\n",
      "North Summit Ave => North Summit Avenue\n",
      "Summit Ave => Summit Avenue\n",
      "S Howell Ave => S Howell Avenue\n",
      "E Wisconsin Ave => E Wisconsin Avenue\n",
      "Wisconsin Ave => Wisconsin Avenue\n",
      "N. Prospect Ave => N. Prospect Avenue\n",
      "W Appleton Ave => W Appleton Avenue\n",
      "Miller Pkwy => Miller Parkway\n",
      "N. Industrial Rd. => N. Industrial Road\n",
      "N. Port Washington Rd. => N. Port Washington Road\n",
      "W Sunset Dr => W Sunset Drive\n",
      "Dr Martin Luther King Dr => Dr Martin Luther King Drive\n",
      "N9581 Bancroft Dr => N9581 Bancroft Drive\n",
      "E Capitol Dr => E Capitol Drive\n",
      "W Oakwood Part Ct => W Oakwood Part Court\n",
      "Manchester Ct => Manchester Court\n",
      "['Highway 41', 'County Highway NN', 'Highway 167 West', 'County Road O', '53076', 'Highway W', 'North Highway 83', 'State Road 164', 'State Highway 31']\n"
     ]
    }
   ],
   "source": [
    "# Test update street type function\n",
    "unchanged_names = []\n",
    "for st_type, ways in st_types.iteritems():\n",
    "    for name in ways:\n",
    "        m = street_type_re.search(name)\n",
    "        if m.group() in mapping_street_name.keys():\n",
    "            better_name = update_street_name(name, mapping_street_name)\n",
    "            print name, '=>', better_name\n",
    "        elif name in changes_street_name.keys():\n",
    "            better_name = update_street_name(name, changes_street_name)\n",
    "            print name, '=>', better_name\n",
    "        else:\n",
    "            unchanged_names.append(name)\n",
    "print unchanged_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53403-9998 => 53403\n",
      "1729 => None\n",
      "WI => None\n",
      "53203-3002 => 53203\n",
      "53202-2001 => 53202\n",
      "53212-4099 => 53212\n",
      "53212-3839 => 53212\n"
     ]
    }
   ],
   "source": [
    "# Test update postcode function\n",
    "for pc_name, ways in pc_names.iteritems():\n",
    "    for name in ways:\n",
    "        better_pc_name = update_postcode(name, mapping_postcode)\n",
    "        print pc_name, '=>', better_pc_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In applying these corrections, we can see from the printed results that all street names and postal codes found to be inconsistent during our audit have been either corrected, skipped, or omitted from the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export (w/ changes) to CSV File\n",
    "Previously defined update functions to correct street name and postal code inconsistencies have been applied to the export function, which was written as exercises throughout the SQL Data Wrangling course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Begin preparing to export cleaned data to .csv files\n",
    "import csv\n",
    "import codecs\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import cerberus\n",
    "\n",
    "import schema\n",
    "\n",
    "OSM_PATH = \"milwaukee_wisconsin.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Mappings\n",
    "mapping_street_name = {'Ave': 'Avenue', \n",
    "           'Ave.': 'Avenue',\n",
    "           'Blvd': 'Boulevard',\n",
    "           'Ct': 'Court',\n",
    "           'Dr': 'Drive', \n",
    "           'Pkwy': 'Parkway',\n",
    "           'Rd': 'Road',\n",
    "           'Rd.': 'Road',\n",
    "           'St': 'Street',\n",
    "           'St.': 'Street'}\n",
    "\n",
    "changes_street_name = {'HWY 164': 'Highway 164',\n",
    "                       'N6620 HWY 164': 'N6620 Highway 164'}\n",
    "\n",
    "skip_street_name = ['53076']\n",
    "\n",
    "mapping_postcode = {'53202-2001': '53202',\n",
    "                    '53203-3002': '53203',\n",
    "                    '53212-3839': '53212',\n",
    "                    '53212-4099': '53212',\n",
    "                    '53403-9998': '53403',\n",
    "                    '53217-5399': '53217',\n",
    "                    'Milwaukee WI, 53222': '53222'}\n",
    "skip_postcode = ['WI', '1729']\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "# Table: nodes.csv\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "# Table: nodes_tags.csv\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "# Table: ways.csv\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "# Table: ways_tags.csv\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "# Table: ways_nodes.csv\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Update street names and postcodes\n",
    "def update_street_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m and m.group() in mapping.keys():\n",
    "        temp_name = name\n",
    "        name = re.sub(street_type_re, mapping[m.group()], name)\n",
    "        # Print name changes as they occur\n",
    "#        print temp_name, '=>', name\n",
    "    return name\n",
    "\n",
    "def update_postcode(name, mapping):\n",
    "    m = postcode_re.search(name)\n",
    "    if not m:\n",
    "        if name in mapping.keys():\n",
    "            name = mapping[name]\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    if element.tag=='node':\n",
    "        for i in node_attr_fields:\n",
    "            node_attribs[i]=element.attrib[i]\n",
    "            \n",
    "    if element.tag=='way':\n",
    "        for i in way_attr_fields:\n",
    "            way_attribs[i]=element.attrib[i]\n",
    "        \n",
    "    for tag in element.iter(\"tag\"):\n",
    "        dic={}\n",
    "        attributes=tag.attrib\n",
    "        kvalue = tag.attrib['k']\n",
    "        vvalue = tag.attrib['v']\n",
    "        if problem_chars.search(kvalue):\n",
    "            continue\n",
    "        if vvalue in skip_street_name or vvalue in skip_postcode:\n",
    "            continue\n",
    "        if kvalue.startswith('addr:'):\n",
    "            if kvalue == 'addr:street':\n",
    "                vvalue_temp = vvalue\n",
    "                vvalue = update_street_name(vvalue, mapping_street_name)\n",
    "                if vvalue_temp != vvalue:\n",
    "                    print vvalue_temp, '=>', vvalue                \n",
    "            elif kvalue == 'addr:postcode':\n",
    "                vvalue_temp = vvalue\n",
    "                vvalue = update_postcode(vvalue, mapping_postcode)\n",
    "                if vvalue_temp != vvalue:\n",
    "                    print vvalue_temp, '=>', vvalue\n",
    "        \n",
    "        tag.attrib['k'] = kvalue\n",
    "        tag.attrib['v'] = vvalue\n",
    "        \n",
    "        if element.tag=='node':\n",
    "            dic['id']=node_attribs['id']\n",
    "        else:\n",
    "            dic['id']=way_attribs['id']\n",
    "        dic['value']=attributes['v']\n",
    "        \n",
    "        colon_k=LOWER_COLON.search(tag.attrib['k'])\n",
    "        if colon_k:\n",
    "            index = tag.attrib['k'].find(':')\n",
    "            if index > 0:\n",
    "                dic['type'] = tag.attrib['k'][:index]\n",
    "                dic['key'] = tag.attrib['k'][index+1:]\n",
    "            \n",
    "        else:\n",
    "            dic['key']=attributes['k']\n",
    "            dic['type']='regular'\n",
    "        \n",
    "        tags.append(dic)\n",
    "    \n",
    "    if element.tag=='way':\n",
    "        position=0\n",
    "        for nd in element.iter(\"nd\"):\n",
    "            way_node_dic={}\n",
    "            way_node_dic['id']=way_attribs['id']\n",
    "            way_node_dic['node_id']=nd.attrib['ref']\n",
    "            way_node_dic['position']=position\n",
    "            position = position + 1\n",
    "            way_nodes.append(way_node_dic)\n",
    "            \n",
    "    if element.tag == 'node':\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    elif element.tag == 'way':\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W Fairy Chasm Rd => W Fairy Chasm Road\n",
      "Milwaukee WI, 53222 => 53222\n",
      "North Murray Ave => North Murray Avenue\n",
      "Norhardt Dr => Norhardt Drive\n",
      "Norhardt Dr => Norhardt Drive\n",
      "Norhardt Dr => Norhardt Drive\n",
      "E Brady St => E Brady Street\n",
      "W Capitol Dr => W Capitol Drive\n",
      "S7959 Racine Ave => S7959 Racine Avenue\n",
      "S 108th St => S 108th Street\n",
      "W National Ave => W National Avenue\n",
      "S 108th St => S 108th Street\n",
      "Scenic Ct => Scenic Court\n",
      "Anthony Ave. => Anthony Avenue\n",
      "Village Square Dr => Village Square Drive\n",
      "W. Wisconsin Ave. => W. Wisconsin Avenue\n",
      "W. Wisconsin Ave. => W. Wisconsin Avenue\n",
      "N. Main St => N. Main Street\n",
      "S. Main St => S. Main Street\n",
      "W North Ave => W North Avenue\n",
      "W North Ave => W North Avenue\n",
      "W Watertown Plank Rd => W Watertown Plank Road\n",
      "N Green Bay Rd => N Green Bay Road\n",
      "N Green Bay Rd => N Green Bay Road\n",
      "North 51st St. => North 51st Street\n",
      "N Green Bay Rd => N Green Bay Road\n",
      "N Green Bay Rd => N Green Bay Road\n",
      "N Green Bay Rd => N Green Bay Road\n",
      "W Donges Bay Rd => W Donges Bay Road\n",
      "Cedarburg Rd => Cedarburg Road\n",
      "W Mequon Rd => W Mequon Road\n",
      "McCanna Pkwy => McCanna Parkway\n",
      "W Forest Home Ave => W Forest Home Avenue\n",
      "South Kinnickinnic Ave => South Kinnickinnic Avenue\n",
      "West Forest Home Ave => West Forest Home Avenue\n",
      "West Forest Home Ave => West Forest Home Avenue\n",
      "West Forest Home Ave => West Forest Home Avenue\n",
      "W Appleton Ave => W Appleton Avenue\n",
      "E. North Ave. => E. North Avenue\n",
      "Wegge Ct => Wegge Court\n",
      "Wegge Ct => Wegge Court\n",
      "S Pine St => S Pine Street\n",
      "S Main St => S Main Street\n",
      "S 108th St => S 108th Street\n",
      "Harwood Ave => Harwood Avenue\n",
      "Main St => Main Street\n",
      "Swenson Dr => Swenson Drive\n",
      "E Moreland Blvd => E Moreland Boulevard\n",
      "53217-5399 => 53217\n",
      "Main St => Main Street\n",
      "South 108th St => South 108th Street\n",
      "Washington Ave => Washington Avenue\n",
      "George Towne Dr => George Towne Drive\n",
      "W68N611 Evergreen Blvd => W68N611 Evergreen Boulevard\n",
      "1101 W Brown Deer Rd => 1101 W Brown Deer Road\n",
      "100 Franklin St. => 100 Franklin Street\n",
      "E Ogden Ave => E Ogden Avenue\n",
      "West County Line Rd => West County Line Road\n",
      "W. Michigan Ave. => W. Michigan Avenue\n",
      "E Wisconsin Ave => E Wisconsin Avenue\n",
      "N. Port Washington Rd. => N. Port Washington Road\n",
      "S 13th St => S 13th Street\n",
      "S Howell Ave => S Howell Avenue\n",
      "N Port Washington Rd => N Port Washington Road\n",
      "N Rochester St => N Rochester Street\n",
      "N 124th St => N 124th Street\n",
      "W Oakwood Part Ct => W Oakwood Part Court\n",
      "N9581 Bancroft Dr => N9581 Bancroft Drive\n",
      "Milwaukee Ave => Milwaukee Avenue\n",
      "E Sumner St => E Sumner Street\n",
      "Miller Pkwy => Miller Parkway\n",
      "E Capitol Dr => E Capitol Drive\n",
      "W Layton Ave => W Layton Avenue\n",
      "W Sunset Dr => W Sunset Drive\n",
      "N Grandview  Blvd => N Grandview  Boulevard\n",
      "21st St => 21st Street\n",
      "Wisconsin Ave => Wisconsin Avenue\n",
      "W Grand Ave => W Grand Avenue\n",
      "Summit Ave => Summit Avenue\n",
      "W Fond du Lac Ave => W Fond du Lac Avenue\n",
      "N. Commerce St. => N. Commerce Street\n",
      "North Oakland Ave. => North Oakland Avenue\n",
      "N. Prospect Ave. => N. Prospect Avenue\n",
      "N. Prospect Ave. => N. Prospect Avenue\n",
      "N. Prospect Ave. => N. Prospect Avenue\n",
      "N. Prospect Ave. => N. Prospect Avenue\n",
      "N. Prospect Ave => N. Prospect Avenue\n",
      "N. Weil St. => N. Weil Street\n",
      "S. Jefferson St. => S. Jefferson Street\n",
      "N. Industrial Rd. => N. Industrial Road\n",
      "N. Industrial Rd. => N. Industrial Road\n",
      "E. North Ave. => E. North Avenue\n",
      "E. North Ave. => E. North Avenue\n",
      "N. Prospect Ave. => N. Prospect Avenue\n",
      "E. North Ave. => E. North Avenue\n",
      "N. Prospect Ave. => N. Prospect Avenue\n",
      "E. North Ave. => E. North Avenue\n",
      "E. North Ave. => E. North Avenue\n",
      "E. North Ave. => E. North Avenue\n",
      "E. North Ave. => E. North Avenue\n",
      "N. Prospect Ave => N. Prospect Avenue\n",
      "N. Industrial Rd. => N. Industrial Road\n",
      "N Weil St => N Weil Street\n",
      "N. Commerce St. => N. Commerce Street\n",
      "E. North Ave. => E. North Avenue\n",
      "East Kensington Blvd => East Kensington Boulevard\n",
      "Golf Rd => Golf Road\n",
      "North Murray Ave => North Murray Avenue\n",
      "W Appleton Ave => W Appleton Avenue\n",
      "Manchester Ct => Manchester Court\n",
      "Manchester Ct => Manchester Court\n",
      "W Sumner St => W Sumner Street\n",
      "North Summit Ave => North Summit Avenue\n",
      "N Pine St => N Pine Street\n",
      "N Pine St => N Pine Street\n",
      "N Pine St => N Pine Street\n",
      "N Pine St => N Pine Street\n",
      "N Pine St => N Pine Street\n",
      "Milwaukee Ave => Milwaukee Avenue\n",
      "Milwaukee Ave => Milwaukee Avenue\n",
      "53403-9998 => 53403\n",
      "N Main St => N Main Street\n",
      "Dr Martin Luther King Dr => Dr Martin Luther King Drive\n",
      "Dr Martin Luther King Dr => Dr Martin Luther King Drive\n",
      "Dr Martin Luther King Dr => Dr Martin Luther King Drive\n",
      "53203-3002 => 53203\n",
      "53212-4099 => 53212\n",
      "53202-2001 => 53202\n",
      "53212-3839 => 53212\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Database Queries\n",
    "For this project, the 'sqlite3' library was imported to allow us to query the database directly through the ipython notebook. Additionally, a couple of functions were developed to print query results in a readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def print_results(db_name, query):\n",
    "    db = sqlite3.connect(db_name)\n",
    "    c = db.cursor()\n",
    "    c.execute(query)\n",
    "    rows = c.fetchall()\n",
    "    \n",
    "    for row in rows:\n",
    "        line = ''\n",
    "        for element in row:\n",
    "            if isinstance(element, basestring):\n",
    "                element = element.encode('utf-8')\n",
    "            else:\n",
    "                element = str(element)\n",
    "            line = line + element + '\\t'\n",
    "        print line\n",
    "    db.close()\n",
    "\n",
    "def print_results_2(db_name, query):\n",
    "    db = sqlite3.connect(db_name)\n",
    "    c = db.cursor()\n",
    "    c.execute(query)\n",
    "    rows = c.fetchall()\n",
    "\n",
    "    for row in rows:\n",
    "        print row\n",
    "\n",
    "    db.close()\n",
    "\n",
    "db_name = 'milwaukee_osm.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Database Information (Schema and Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Table Names----------\n",
      "[(u'nodes',), (u'nodes_tags',), (u'ways',), (u'ways_tags',), (u'ways_nodes',)]\n",
      "\n",
      "------------Schema-------------\n",
      "table \t\tnodes\n",
      "line count \t137034\n",
      "CREATE TABLE nodes(id, lat, lon, user, uid, version, changeset, timestamp)\n",
      "\n",
      "table \t\tnodes_tags\n",
      "line count \t162854\n",
      "CREATE TABLE nodes_tags(id, key, value, type)\n",
      "\n",
      "table \t\tways\n",
      "line count \t163025\n",
      "CREATE TABLE ways(id, user, uid, version, changeset, timestamp)\n",
      "\n",
      "table \t\tways_tags\n",
      "line count \t163026\n",
      "CREATE TABLE ways_tags(id, key, value, type)\n",
      "\n",
      "table \t\tways_nodes\n",
      "line count \t163027\n",
      "CREATE TABLE ways_nodes(id, node_id, position)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show Schema and Tables\n",
    "con = sqlite3.connect(db_name)\n",
    "cursor = con.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "print '----------Table Names----------'\n",
    "print(cursor.fetchall())\n",
    "print\n",
    "\n",
    "\n",
    "query = 'SELECT * FROM sqlite_master;'\n",
    "db = sqlite3.connect(db_name)\n",
    "c = db.cursor()\n",
    "c.execute(query)\n",
    "rows = c.fetchall()\n",
    "\n",
    "print '------------Schema-------------'\n",
    "for row in rows:\n",
    "    print row[0], '\\t\\t', row[1]\n",
    "    print 'line count', '\\t', row[3]\n",
    "    print row[4]\n",
    "    print\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The database consists of 5 tables (nodes, nodes_tags, ways, ways_tags, and ways_nodes), created from CSV data which was generated in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort cities by count, descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Milwaukee\t2233\t\n",
      "Racine\t638\t\n",
      "Mount Pleasant\t238\t\n",
      "Burlington\t41\t\n",
      "Sturtevant\t35\t\n",
      "Caledonia\t32\t\n",
      "Waukesha\t32\t\n",
      "MIlwaukee\t23\t\n",
      "Brown Deer\t21\t\n",
      "West Allis\t21\t\n",
      "Hartland\t20\t\n",
      "Wauwatosa\t20\t\n",
      "Brookfield\t19\t\n",
      "Cedarburg\t19\t\n",
      "Glendale\t19\t\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT tags.value, COUNT(*) as count\n",
    "            FROM (SELECT * FROM nodes_tags UNION ALL\n",
    "                    SELECT * FROM ways_tags) tags\n",
    "            WHERE tags.key LIKE \"city\"\n",
    "            GROUP BY tags.value\n",
    "            ORDER BY count DESC\n",
    "            LIMIT 15;'''\n",
    "print_results(db_name, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a large portion of the nodes are located in Milwaukee, there are a few which contain cities in the Milwaukee metropolitan area. Some cities (like Racine and Mount Pleasant) are actually a fairly long distance away from Milwaukee (25 miles between city centers for Milwaukee -> Racine).\n",
    "\n",
    "Postal code data seems to be okay, with all listed postal codes starting with \"53XXX\". This indicates all postal codes are within some vicinity of Milwaukee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53202\t1372\t\n",
      "53212\t339\t\n",
      "53203\t236\t\n",
      "53233\t132\t\n",
      "53205\t96\t\n",
      "53211\t91\t\n",
      "53204\t67\t\n",
      "53215\t47\t\n",
      "53027\t45\t\n",
      "53105\t45\t\n",
      "53216\t28\t\n",
      "53222\t25\t\n",
      "53186\t23\t\n",
      "53223\t23\t\n",
      "53029\t22\t\n",
      "53012\t20\t\n",
      "53207\t20\t\n",
      "53402\t19\t\n",
      "53213\t17\t\n",
      "53217\t16\t\n"
     ]
    }
   ],
   "source": [
    "# Show all postal codes listed in database to ensure replacement function worked correctly\n",
    "\n",
    "query = \"\"\"SELECT tags.value, COUNT(*) as count\n",
    "FROM (SELECT * FROM nodes_tags\n",
    "\t\tUNION ALL\n",
    "\t\tSELECT * FROM ways_tags) tags\n",
    "WHERE tags.key = 'postcode'\n",
    "GROUP BY tags.value\n",
    "ORDER BY count DESC\n",
    "LIMIT 20;\"\"\"\n",
    "\n",
    "print_results(db_name, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File sizes\n",
    "    milwaukee_wisconsin.osm..... 188.8 MB\n",
    "    milwaukee_osm.db............ 256.2 MB\n",
    "    nodes.csv...................  70.5 MB\n",
    "    nodes_tags.csv..............   2.4 MB\n",
    "    ways.csv....................   5.7 MB\n",
    "    ways_tags.csv...............  15.5 MB\n",
    "    ways_nodes.csv..............  24.6 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Nodes and Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Nodes:\n",
      "----------------\n",
      "840764\t\n",
      "vs. 840763 (From iterparse method)\n",
      "\n",
      "Number of Ways:\n",
      "---------------\n",
      "94039\t\n",
      "vs. 94038 (From iterparse method)\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT COUNT(*) FROM nodes;\"\n",
    "print 'Number of Nodes:'\n",
    "print '----------------'\n",
    "print_results(db_name, query)\n",
    "print 'vs.', tags['node'], '(From iterparse method)'\n",
    "\n",
    "print \n",
    "\n",
    "query = \"SELECT COUNT(*) FROM ways;\"\n",
    "print 'Number of Ways:'\n",
    "print '---------------'\n",
    "print_results(db_name, query)\n",
    "print 'vs.', tags['way'], '(From iterparse method)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Unique Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users\n",
      "----------------------\n",
      "641\t\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"SELECT COUNT(DISTINCT(e.uid))\n",
    "FROM (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e;\"\"\"\n",
    "print 'Number of unique users'\n",
    "print '----------------------'\n",
    "print_results(db_name, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 contributing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 contributing users:\n",
      "--------------------------\n",
      "woodpeck_fixbot\t178980\t\n",
      "shuui\t136230\t\n",
      "ItalianMustache\t118347\t\n",
      "reschultzed\t61072\t\n",
      "bbauter\t29048\t\n",
      "Gary Cox\t26439\t\n",
      "hogrod\t25616\t\n",
      "iandees\t25396\t\n",
      "Mulad\t22393\t\n",
      "TIGERcnl\t21652\t\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT e.user, COUNT(*) as num\n",
    "FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\n",
    "GROUP BY e.user\n",
    "ORDER BY num DESC\n",
    "LIMIT 10;'''\n",
    "print 'Top 10 contributing users:'\n",
    "print '--------------------------'\n",
    "print_results(db_name, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of users appearing only once (having 1 post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users appearing only once:\n",
      "------------------------------------\n",
      "113\t\n"
     ]
    }
   ],
   "source": [
    "query = ''' SELECT COUNT(*)\n",
    "            FROM\n",
    "                (SELECT e.user, COUNT(*) as num\n",
    "                FROM (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e\n",
    "                GROUP BY e.user\n",
    "                HAVING num=1) u;'''\n",
    "print 'Number of users appearing only once:'\n",
    "print '------------------------------------'\n",
    "print_results(db_name, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "#### Top 10 Appearing Amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 appearing amenities:\n",
      "---------------------------\n",
      "parking_entrance\t896\t\n",
      "school\t627\t\n",
      "restaurant\t299\t\n",
      "bench\t285\t\n",
      "fast_food\t144\t\n",
      "grave_yard\t129\t\n",
      "fuel\t116\t\n",
      "parking\t86\t\n",
      "cafe\t83\t\n",
      "bicycle_parking\t68\t\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT value, COUNT(*) as num\n",
    "            FROM nodes_tags\n",
    "            WHERE key=\"amenity\"\n",
    "            GROUP BY value\n",
    "            ORDER BY num DESC\n",
    "            LIMIT 10;'''\n",
    "print 'Top 10 appearing amenities:'\n",
    "print '---------------------------'\n",
    "print_results(db_name, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of coffee shop / cafe locations, grouped by company (very important to me!)\n",
    "It should be noted that Starbucks appears multiple times in this list (as well as some other cafes, such as Colectivo). This database could benefit from some data cleaning to standardize the names of these companies to a single spelling, to avoid redundant list items like those found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starbucks\t9\t\n",
      "Starbucks Coffee\t3\t\n",
      "Stone Creek Coffee\t3\t\n",
      "Colectivo Coffee\t2\t\n",
      "Dunkin' Donuts\t2\t\n",
      "Starbuck's\t2\t\n",
      "2894 On Main\t1\t\n",
      "600 East Cafe\t1\t\n",
      "8th Note Coffee House\t1\t\n",
      "Alderaan Coffee\t1\t\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT nodes_tags.value, COUNT(*) as num\n",
    "            FROM nodes_tags, (\n",
    "                 SELECT *\n",
    "                   FROM nodes_tags \n",
    "                   WHERE key=\"amenity\" AND value = \"cafe\") as cafe\n",
    "            WHERE nodes_tags.id = cafe.id AND nodes_tags.key=\"name\"\n",
    "            GROUP BY nodes_tags.value\n",
    "            ORDER BY num DESC\n",
    "            LIMIT 10'''\n",
    "print_results(db_name, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most popular cuisines in the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "american\t26\t\n",
      "pizza\t25\t\n",
      "italian\t16\t\n",
      "sandwich\t15\t\n",
      "chinese\t13\t\n",
      "burger\t10\t\n",
      "american_new\t7\t\n",
      "mexican\t7\t\n",
      "japanese\t6\t\n",
      "regional\t5\t\n",
      "greek\t4\t\n",
      "german\t3\t\n",
      "seafood\t3\t\n",
      "steak_house\t3\t\n",
      "vietnamese\t3\t\n",
      "asian\t2\t\n",
      "bagel\t2\t\n",
      "diner\t2\t\n",
      "ethiopian\t2\t\n",
      "indian\t2\t\n",
      "irish\t2\t\n",
      "korean\t2\t\n",
      "new_american\t2\t\n",
      "new_orleans\t2\t\n",
      "world\t2\t\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT nodes_tags.value, COUNT(*) as num\n",
    "            FROM nodes_tags\n",
    "                JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value='restaurant') i\n",
    "                ON nodes_tags.id = i.id\n",
    "            WHERE nodes_tags.key = 'cuisine'\n",
    "            GROUP BY nodes_tags.value\n",
    "            ORDER BY num DESC\n",
    "            LIMIT 25;'''\n",
    "print_results(db_name, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great! Although I wish there were more, there are 2 Korean restaurants in the city and surrounding area! I'm curious to find out the names of these restaurants so I can look into them further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korean\tSeoul Korean Restaurant\t\n",
      "korean\tStone Bowl Grill\t\n",
      "new_orleans\tEvolution Gastro Pong\t\n",
      "new_orleans\tThe Brass Alley\t\n"
     ]
    }
   ],
   "source": [
    "# Name of all Korean restaurants\n",
    "query = '''SELECT restaurant.value, nodes_tags.value\n",
    "            FROM nodes_tags, (\n",
    "                 SELECT *\n",
    "                   FROM nodes_tags \n",
    "                   WHERE key=\"cuisine\" AND (value = \"korean\" OR (value = \"new_orleans\"))) as restaurant\n",
    "            WHERE nodes_tags.id = restaurant.id AND nodes_tags.key=\"name\"'''\n",
    "print_results(db_name, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They both offer Korean BBQ!! And have pretty good reviews on Yelp!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most popular grocery stores\n",
    "Pick n' Save seems to be the winner here, but there are a few local markets available, and of course a couple of Walmart's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aldi\t11\t\n",
      "Piggly Wiggly\t8\t\n",
      "Pick n' Save\t7\t\n",
      "Pick 'n' Save\t3\t\n",
      "Sentry Foods\t3\t\n",
      "Walmart Supercenter\t3\t\n",
      "Outpost Natural Foods\t2\t\n",
      "Pick 'n Save\t2\t\n",
      "Pick'n Save\t2\t\n",
      "Sendik's\t2\t\n"
     ]
    }
   ],
   "source": [
    "query = '''SELECT nodes_tags.value, COUNT(*) as num\n",
    "            FROM nodes_tags, (\n",
    "                 SELECT *\n",
    "                   FROM nodes_tags \n",
    "                   WHERE key=\"shop\" AND (value = \"supermarket\")) as grocery\n",
    "            WHERE nodes_tags.id = grocery.id AND nodes_tags.key=\"name\"\n",
    "            GROUP BY nodes_tags.value\n",
    "            ORDER BY num DESC\n",
    "            LIMIT 10;'''\n",
    "print_results(db_name, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the data did require some cleaning for consistency, but appeared to be accurate with respects to all nodes being within the Milwaukee metropolitan area. I would suggest further cleaning in the names of amenities to allow more accurate grouping with SQL queries (for example: \"StarBucks\" vs. \"Starbucks\", or \"Pick N Save\" vs. \"Pick n Save\"). \n",
    "\n",
    "This task, however, is quite labor intensive. While it is something that could be done to an extent programmatically using regular expressions, it will most likely also require a significant amount of manual user input to be performed completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## References\n",
    "Sample Project - https://gist.github.com/carlward/54ec1c91b62a5f911c42#file-sample_project-md"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
